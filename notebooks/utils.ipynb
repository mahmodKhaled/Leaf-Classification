{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_paths(images_ids):\n",
    "    images_paths = []\n",
    "    img = plt.imread('C:/Users/mahmo/Desktop/Leaf-Classification/input/images/1.jpg')\n",
    "    source_folder = 'C:/Users/mahmo/Desktop/Leaf-Classification/input/images/'\n",
    "    for id in images_ids:\n",
    "        img_path = source_folder + str(id) + '.jpg'\n",
    "        images_paths.append(img_path)\n",
    "    return images_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_some_images(images_paths):\n",
    "    fig , axis = plt.subplots(2,4)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(20)\n",
    "    # load images\n",
    "    images = []\n",
    "    for path in images_paths:\n",
    "        images.append(plt.imread(path))\n",
    "    i , j = 0 , 0\n",
    "    for img in images:\n",
    "        axis[i,j].imshow(img,cmap='gray')\n",
    "        j = j + 1\n",
    "        if j == 4:\n",
    "            i = i + 1\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    # read data from csv file in input folder\n",
    "    cur_dir = os.getcwd()\n",
    "    file_path = 'C:/Users/mahmo/Desktop/Leaf-Classification/input/' + file_name\n",
    "    data = pd.read_csv(os.path.join(cur_dir,file_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['species','id'])\n",
    "    y_train = train_data[['species']]\n",
    "    # rename test variable and drop id column from the test dat\n",
    "    X_test = test_data.drop(columns=['id'])\n",
    "    # view correlations between columns\n",
    "    correlation_matrix = X_train.corr()\n",
    "    # take absolute values\n",
    "    correlation_matrix_abs = correlation_matrix.abs()\n",
    "    upper_matrix = correlation_matrix_abs.where(np.triu(np.ones(correlation_matrix_abs.shape),k=1).astype(np.bool_))\n",
    "    # check to see if there is a column has a correlation higher than 0.9\n",
    "    correlation_threshold = 0.9\n",
    "    col_with_high_correlation = [col for col in upper_matrix.columns if np.any(upper_matrix[col] > correlation_threshold)]\n",
    "    # drop shape columns from X_train and also X_test\n",
    "    X_train = X_train.drop(columns=col_with_high_correlation)\n",
    "    X_test = X_test.drop(columns=col_with_high_correlation)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "    # apply the transformation to the X_test data\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), index = X_test.index, columns = X_test.columns)\n",
    "    y_train_encoded = pd.get_dummies(y_train['species'])\n",
    "    return X_train_scaled, y_train_encoded, X_test_scaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_paths(images_ids):\n",
    "    images_paths = []\n",
    "    img = plt.imread('C:/Users/mahmo/Desktop/Leaf-Classification/input/images/1.jpg')\n",
    "    source_folder = 'C:/Users/mahmo/Desktop/Leaf-Classification/input/images/'\n",
    "    for id in images_ids:\n",
    "        img_path = source_folder + str(id) + '.jpg'\n",
    "        images_paths.append(img_path)\n",
    "    return images_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_some_images(images_paths):\n",
    "    fig , axis = plt.subplots(2,4)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(20)\n",
    "    # load images\n",
    "    images = []\n",
    "    for path in images_paths:\n",
    "        images.append(plt.imread(path))\n",
    "    i , j = 0 , 0\n",
    "    for img in images:\n",
    "        axis[i,j].imshow(img,cmap='gray')\n",
    "        j = j + 1\n",
    "        if j == 4:\n",
    "            i = i + 1\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    # read data from csv file in input folder\n",
    "    cur_dir = os.getcwd()\n",
    "    file_path = 'C:/Users/mahmo/Desktop/Leaf-Classification/input/' + file_name\n",
    "    data = pd.read_csv(os.path.join(cur_dir,file_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['species','id'])\n",
    "    y_train = train_data[['species']]\n",
    "    # rename test variable and drop id column from the test dat\n",
    "    X_test = test_data.drop(columns=['id'])\n",
    "    # determine unique classes in the dataset\n",
    "    y_train_unique = pd.unique(y_train['species'])\n",
    "    # length of unique classes\n",
    "    y_train_unique_length = len(y_train_unique)\n",
    "    # view correlations between columns\n",
    "    correlation_matrix = X_train.corr()\n",
    "    # take absolute values\n",
    "    correlation_matrix_abs = correlation_matrix.abs()\n",
    "    upper_matrix = correlation_matrix_abs.where(np.triu(np.ones(correlation_matrix_abs.shape),k=1).astype(np.bool_))\n",
    "    # check to see if there is a column has a correlation higher than 0.9\n",
    "    correlation_threshold = 0.9\n",
    "    col_with_high_correlation = [col for col in upper_matrix.columns if np.any(upper_matrix[col] > correlation_threshold)]\n",
    "    # drop shape columns from X_train and also X_test\n",
    "    X_train = X_train.drop(columns=col_with_high_correlation)\n",
    "    X_test = X_test.drop(columns=col_with_high_correlation)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "    # apply the transformation to the X_test data\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), index = X_test.index, columns = X_test.columns)\n",
    "    y_train_encoded = pd.get_dummies(y_train['species'])\n",
    "    return X_train_scaled, y_train_encoded, X_test_scaled, y_train_unique_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mycallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if logs['accuracy'] > 0.99:\n",
    "            print('\\nReached required accuracy above 99% at epoch', epochs, ', so cancel training!')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "def DenseMLP(input_shape, hidden_size, output_size, dropout_rate, dropout = False):\n",
    "    if dropout:\n",
    "        # (batch_size,input_shape[0],input_shape[1])\n",
    "        model = Sequential([\n",
    "        # input layer\n",
    "        Input(shape=(input_shape[-1])),\n",
    "        # one hidden layer\n",
    "        Dense(units = hidden_size, activation = 'tanh'),\n",
    "        # dropout layer\n",
    "        Dropout(rate = dropout_rate),\n",
    "        # output layer\n",
    "        Dense(units = output_size, activation = 'softmax')\n",
    "        ])\n",
    "    else:\n",
    "        model = Sequential([\n",
    "        # input layer\n",
    "        Input(shape=(input_shape[-1])),\n",
    "        # one hidden layer\n",
    "        Dense(units = hidden_size, activation = 'tanh'),\n",
    "        # output layer\n",
    "        Dense(units = output_size, activation = 'softmax')\n",
    "        ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training function which accepts many hyperparameters\n",
    "def training(model, X, y, batch_size, optimizer, learning_rate_scheduler, custom_call_back):\n",
    "    # compile the model\n",
    "    model.compile(optimizer = optimizer, loss = CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "    # callbacks\n",
    "    if learning_rate_scheduler is not None:\n",
    "        lr_scheduler_callback = learning_rate_scheduler\n",
    "        if custom_call_back is None:\n",
    "            history = model.fit(x= X,y= y, batch_size= batch_size, epochs = 500, verbose= 0, \n",
    "                            callbacks= [lr_scheduler_callback], validation_split= 0.2)\n",
    "        else:\n",
    "            on_epoch_end_callback = Mycallback()\n",
    "            # model fit\n",
    "            history = model.fit(x= X,y= y, batch_size= batch_size, epochs = 500, verbose= 0, \n",
    "                                callbacks= [lr_scheduler_callback, on_epoch_end_callback], validation_split= 0.2)\n",
    "    else:\n",
    "        if custom_call_back is None:\n",
    "            history = model.fit(x= X,y= y, batch_size= batch_size, epochs = 500, verbose= 0, validation_split= 0.2)\n",
    "        else:\n",
    "            on_epoch_end_callback = Mycallback()\n",
    "            # model fit\n",
    "            history = model.fit(x= X,y= y, batch_size= batch_size, \n",
    "                                epochs = 500, verbose= 0, callbacks= [on_epoch_end_callback], validation_split= 0.2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation function which loads the trained model and evaluate its performance on train/test set\n",
    "def evaluation(model, X, y, batch_size):\n",
    "    results = model.evaluate(x= X, y= y, batch_size = batch_size, verbose= 0)\n",
    "    return results[0], results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Curves Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_curves(history, special_title, special_title_var):\n",
    "    if special_title_var is None:\n",
    "        title_loss = 'Model loss per epoch ' + special_title\n",
    "        title_accuracy = 'Model accuracy per epoch ' + special_title\n",
    "    else:    \n",
    "        title_loss = 'Model loss per epoch ' + special_title + ' ' + str(special_title_var)\n",
    "        title_accuracy = 'Model accuracy per epoch ' + special_title + ' ' + str(special_title_var)\n",
    "    fig , axis = plt.subplots(nrows=1, ncols=2)\n",
    "    # dimensions of figure\n",
    "    fig.set_figheight(6)\n",
    "    fig.set_figwidth(14)\n",
    "    # loss\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    # accuracy\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    epoch = np.arange(150)\n",
    "    # loss curve\n",
    "    axis[0].plot(loss,label='Train')\n",
    "    axis[0].plot(val_loss,label='Validation')\n",
    "    axis[0].set_xlabel('epoch')\n",
    "    axis[0].set_ylabel('loss')\n",
    "    axis[0].set_title(title_loss)\n",
    "    axis[0].legend()\n",
    "    # accuracy curve\n",
    "    axis[1].plot(accuracy, label='Train')\n",
    "    axis[1].plot(val_accuracy, label='Validation')\n",
    "    axis[1].set_xlabel('epoch')\n",
    "    axis[1].set_ylabel('accuracy')\n",
    "    axis[1].set_title(title_accuracy)\n",
    "    axis[1].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
